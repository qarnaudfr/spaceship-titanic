{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nprint(f\"sklearn version : {sklearn.__version__}\")\n\ntrain_file='/kaggle/input/spaceship-titanic/train.csv'\ntest_file='/kaggle/input/spaceship-titanic/test.csv'","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-06-08T15:23:14.956914Z","iopub.execute_input":"2022-06-08T15:23:14.958588Z","iopub.status.idle":"2022-06-08T15:23:14.967686Z","shell.execute_reply.started":"2022-06-08T15:23:14.958528Z","shell.execute_reply":"2022-06-08T15:23:14.966332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Debugg=False","metadata":{"execution":{"iopub.status.busy":"2022-06-08T16:03:43.62326Z","iopub.execute_input":"2022-06-08T16:03:43.623815Z","iopub.status.idle":"2022-06-08T16:03:43.62941Z","shell.execute_reply.started":"2022-06-08T16:03:43.623776Z","shell.execute_reply":"2022-06-08T16:03:43.628354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_new_variables(data):\n    data['Group'] = data.PassengerId.apply(lambda x : x[0:4])\n    data['Group'] = data.groupby('Group')['Group'].transform('count')\n\n    Luxury_variables = ['RoomService','Spa','VRDeck','FoodCourt','ShoppingMall']\n    data[\"Luxury\"] = data[Luxury_variables].sum(axis=1)\n\n    data[\"nbnan\"] = data.isnull().sum(axis=1)\n    \n    data['last_name'] = data['Name'].apply(lambda x:str(x).split(\" \")[-1])\n    data.last_name.value_counts()\n    data['N_Familly_members'] = data.groupby('last_name')['last_name'].transform('count')\n    #data['Luxury_Familly'] = data.groupby('last_name')['Luxury'].transform('sum')\n    data.set_index('PassengerId')\n    \n    newvars  = pd.DataFrame(data[\"Cabin\"].str.split('/', expand=True).values,columns=['Cabin_Deck','Cabin_Number','Cabin_Side'])\n    data = pd.concat([data,newvars],axis=1)\n    return data","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-06-08T16:03:45.824763Z","iopub.execute_input":"2022-06-08T16:03:45.825893Z","iopub.status.idle":"2022-06-08T16:03:45.836499Z","shell.execute_reply.started":"2022-06-08T16:03:45.825848Z","shell.execute_reply":"2022-06-08T16:03:45.835312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\ndef indices_of_top_k(arr, k,reverse=False):\n    if(reverse==False):\n        z = np.array(arr)[0:k]\n    else:\n        z = np.array(arr)[-k-1:]\n    return np.sort(z)\n\nclass TopFeatureSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, feature_importances=None, k=None,reverse=False):\n        self.feature_importances = feature_importances\n        self.k = k\n        self.reverse = reverse\n    def fit(self, X, y=None):\n        if(self.feature_importances!=None):\n            self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k,self.reverse)     \n                \n        return self\n    def transform(self, X):\n        if(self.feature_importances!=None and self.k!=None):\n            return X[:, self.feature_indices_]\n        else :\n            return X","metadata":{"execution":{"iopub.status.busy":"2022-06-08T16:03:49.903974Z","iopub.execute_input":"2022-06-08T16:03:49.904399Z","iopub.status.idle":"2022-06-08T16:03:49.915264Z","shell.execute_reply.started":"2022-06-08T16:03:49.904367Z","shell.execute_reply":"2022-06-08T16:03:49.914077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(train_file)\ndata_sub = pd.read_csv(test_file)\n\nif(Debugg):\n    data = data.iloc[:30]\n    data_sub = data_sub.iloc[:30]\nX_sub = data_sub\n\ndata = add_new_variables(data)\ndata_sub = add_new_variables(data_sub)\nX_sub = add_new_variables(X_sub)\n\nTarget_name = 'Transported'\ny = data[Target_name]\nX = data.drop(columns=[Target_name])\n\n#\"nbnan\",\"ShoppingMall\"\ncolumns_to_drop = [\"Cabin\",\"Name\",'last_name']\nX = X.drop(columns=columns_to_drop)\nX_sub = X_sub.drop(columns=columns_to_drop)\n\nX = X.drop(columns=['PassengerId'])\n\nnumerical_columns = X.select_dtypes(exclude=['object']).columns\ncategorical_columns = X.select_dtypes(include=['object']).columns\n\ndef clean_data(dt):\n    #we first use the information we have gathered so far:\n    #People from Cabin_Deck==G are al from Europa as shown from : sns.histplot(data=data,x='Cabin_Deck',hue='HomePlanet')\n    mask1 = (dt['Cabin_Deck']=='G')\n    mask2 = dt.HomePlanet.isnull()\n    mask = (mask1) & (mask2)\n    dt.loc[mask,'HomePlanet'] = 'Earth' \n    \n    mask1 = (dt['HomePlanet']=='Earth')\n    mask2 = dt.Cabin_Deck.isnull()\n    mask = (mask1) & (mask2)\n    dt.loc[mask,'Cabin_Deck'] = 'G' \n    \n    # Il n'y a pas de VIP qui ont Earth en HomePlanet : sns.catplot(data=data,x='VIP',col='HomePlanet',kind='count')\n    mask1 = (dt['HomePlanet']=='Earth')\n    mask2 = dt.VIP.isnull()\n    mask = (mask1) & (mask2)\n    dt.loc[mask,'VIP'] = False\n    \n    # aucun des VIP n'est en CryoSleep : sns.histplot(data=X,y='VIP',hue='CryoSleep',multiple='stack')\n    mask1 = (dt['CryoSleep']==False)\n    mask2 = dt.VIP.isnull()\n    mask = (mask1) & (mask2)\n    dt.loc[mask,'VIP'] = True \n    \n    mask = (dt['VIP']==True)\n    mask2 = dt.CryoSleep.isnull()\n    mask = (mask1) & (mask2)\n    dt.loc[mask,'CryoSleep'] = False\n    \n    # les gends des decks A B et C sont tous d'europe : sns.histplot(data=data,x='Cabin_Deck',hue='HomePlanet')\n    mask1 = (dt.Cabin_Deck.isin(['A','B','C']))\n    mask2 = dt.HomePlanet.isnull()\n    mask = (mask1) & (mask2)\n    dt.loc[mask,'HomePlanet']='Europa'\n    \n    #Les enfants d'un Age nférieur ou égal à 12 ans n'ont rien dépensé\n    mask1 = dt.Age<=12\n    for col in ['RoomService','Spa','VRDeck','FoodCourt','ShoppingMall']:\n        mask2 = dt[col].isnull()\n        mask = (mask1) & (mask2)\n        dt.loc[mask,col]= 0\n        \n    \n    Luxury_variables = ['RoomService','Spa','VRDeck','FoodCourt','ShoppingMall']\n    dt[\"Luxury\"] = dt[Luxury_variables].sum(axis=1)\n    \n    dt.loc[(dt.CryoSleep.isnull()) & (dt.Luxury == 0), 'CryoSleep'] = True\n    dt.loc[(dt.CryoSleep.isnull()) & (dt.Luxury != 0), 'CryoSleep'] = False\n    \n    # si l'age est manquant, le selectionner sur la base des habitants de la meme planete    \n    dt['Age']=dt['Age'].fillna(dt.groupby('HomePlanet')['Age'].transform(\"median\"))\n    \n    dt[numerical_columns] = dt[numerical_columns].fillna(dt[numerical_columns].median())\n    dt[categorical_columns] = dt[categorical_columns].fillna('Unknown').astype('string')\n    return dt\n\nX = clean_data(X)\nX_sub = clean_data(X_sub)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T16:03:52.348227Z","iopub.execute_input":"2022-06-08T16:03:52.348642Z","iopub.status.idle":"2022-06-08T16:03:52.747254Z","shell.execute_reply.started":"2022-06-08T16:03:52.348611Z","shell.execute_reply":"2022-06-08T16:03:52.746258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(data.corr(),annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T15:47:20.339239Z","iopub.execute_input":"2022-06-08T15:47:20.339661Z","iopub.status.idle":"2022-06-08T15:47:21.206621Z","shell.execute_reply.started":"2022-06-08T15:47:20.339628Z","shell.execute_reply":"2022-06-08T15:47:21.205807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-06-08T15:47:28.295677Z","iopub.execute_input":"2022-06-08T15:47:28.296416Z","iopub.status.idle":"2022-06-08T15:47:28.343074Z","shell.execute_reply.started":"2022-06-08T15:47:28.296377Z","shell.execute_reply":"2022-06-08T15:47:28.342313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.histplot(data=data[data.Luxury==0],x='Age',ax=ax)\nsns.histplot(data=data[data.Luxury!=0],x='Age',ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T14:33:53.106616Z","iopub.execute_input":"2022-06-08T14:33:53.107047Z","iopub.status.idle":"2022-06-08T14:33:53.466166Z","shell.execute_reply.started":"2022-06-08T14:33:53.10701Z","shell.execute_reply":"2022-06-08T14:33:53.464852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_data(data).isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-08T14:46:05.085664Z","iopub.execute_input":"2022-06-08T14:46:05.086095Z","iopub.status.idle":"2022-06-08T14:46:05.14414Z","shell.execute_reply.started":"2022-06-08T14:46:05.086062Z","shell.execute_reply":"2022-06-08T14:46:05.142983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data=data,x='Destination',hue='HomePlanet')","metadata":{"execution":{"iopub.status.busy":"2022-06-08T14:52:14.367956Z","iopub.execute_input":"2022-06-08T14:52:14.368546Z","iopub.status.idle":"2022-06-08T14:52:14.647232Z","shell.execute_reply.started":"2022-06-08T14:52:14.368499Z","shell.execute_reply":"2022-06-08T14:52:14.646394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import set_config\nset_config(display=\"diagram\")\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\ncategorical_preprocessor = Pipeline([\n    #('impcat',SimpleImputer()),#,strategy='constant',fill_value=\"missing_value\")),  # ca ne marche pas car mussing_value set considéré comme un string alors que les autres variables sont objet.\n    ('enc',OrdinalEncoder(handle_unknown=\"use_encoded_value\",unknown_value=-1)),\n     ])\n\nnumerical_preprocessor = Pipeline([\n    #('impnum',SimpleImputer(missing_values=np.nan, strategy='median')),\n    ('sca',StandardScaler()),\n])\n    \npreprocessor = ColumnTransformer(\n    [\n        ('cat_preprocessor', categorical_preprocessor, categorical_columns),\n        ('num_preprocessor', numerical_preprocessor, numerical_columns),\n       \n    ],#sparse_threshold=0, remainder='passthrough',\n)\n\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom xgboost import XGBClassifier\nclassifier = RandomForestClassifier(n_estimators=400, max_leaf_nodes=10,n_jobs=-1, random_state=42)\n#classifier = SGDClassifier(alpha=0.01,random_state=42)\n#classifier = HistGradientBoostingClassifier(learning_rate=0.005, max_leaf_nodes=20, early_stopping=True, n_iter_no_change=5, max_iter=1000)\n\nestimators = [\n    (\"hist\",HistGradientBoostingClassifier(learning_rate=0.005, max_leaf_nodes=20, early_stopping=True, n_iter_no_change=5, max_iter=1000,random_state=42)),\n    (\"forest\",RandomForestClassifier(bootstrap=True,n_estimators=600,max_depth=16,max_leaf_nodes=10,n_jobs=-1, random_state=42,min_samples_leaf=1)),\n   # (\"knn\",KNeighborsClassifier(n_neighbors=40)),\n    #(\"sgd\",SGDClassifier(alpha=0.01,random_state=42)),\n    #(\"log\",LogisticRegression(random_state=42,max_iter=1000)),\n   # (\"xgb\",XGBClassifier(eta=0.005,max_depth=10))\n]\nclassifier = VotingClassifier(estimators, voting='soft')\n\n\nmodel = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"TopFeatureSelector\",TopFeatureSelector(feature_importances=None, k=None)),\n    (\"classifier\",  classifier),\n])\n\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\n\ncv_inner = StratifiedKFold(n_splits=5,shuffle=True,random_state=42) #mega important\ncv_outer = StratifiedKFold(n_splits=5,shuffle=True,random_state=42) #mega important\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,shuffle=True)\n\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-06-08T15:49:39.941785Z","iopub.execute_input":"2022-06-08T15:49:39.942219Z","iopub.status.idle":"2022-06-08T15:49:40.064961Z","shell.execute_reply.started":"2022-06-08T15:49:39.942185Z","shell.execute_reply":"2022-06-08T15:49:40.063822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_results = cross_validate(model,X_train,y_train,cv=cv_outer,error_score='raise',scoring=\"balanced_accuracy\", return_train_score=True)\nfor name in [\"train\", \"test\"]:\n    r = cv_results[f'{name}_score'] \n    print(f\"Score {name}: {r.mean():.3f} +/- {r.std():.3f}\")\n    \nfrom sklearn.model_selection import cross_val_predict\ny_train_pred = cross_val_predict(model,X_train,y_train,cv=cv_outer)\nfrom sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score\nconfusion_matrix(y_train,y_train_pred)\nprint(f\"precision_score = {precision_score(y_train,y_train_pred):.3f}\")\nprint(f\"recall_score = {recall_score(y_train,y_train_pred):.3f}\")\nprint(f\"f1_score = {f1_score(y_train,y_train_pred):.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-08T15:49:42.800299Z","iopub.execute_input":"2022-06-08T15:49:42.801068Z","iopub.status.idle":"2022-06-08T15:49:57.214263Z","shell.execute_reply.started":"2022-06-08T15:49:42.801008Z","shell.execute_reply":"2022-06-08T15:49:57.212842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T15:48:21.324128Z","iopub.execute_input":"2022-06-08T15:48:21.324595Z","iopub.status.idle":"2022-06-08T15:48:22.487886Z","shell.execute_reply.started":"2022-06-08T15:48:21.324553Z","shell.execute_reply":"2022-06-08T15:48:22.48681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = np.linspace(200,1000,100,dtype=int).tolist()\nmax_features = ['auto', 'sqrt']\nmax_depth = np.linspace(5, 30,26).tolist()+['None']\nmin_samples_leaf = [1, 2, 4,8]\nbootstrap = [True, False]# Create the random grid\n\nparam_distributions = {\n    'classifier__forest__n_estimators': n_estimators,\n    'classifier__forest__max_features': max_features,\n    'classifier__forest__max_depth': max_depth,\n    'classifier__forest__min_samples_leaf': min_samples_leaf,\n    'classifier__forest__bootstrap': bootstrap\n}\n\nmodel_random_search = RandomizedSearchCV(\n    model, param_distributions=param_distributions, n_iter=30,cv=cv_inner, verbose=1,n_jobs = -1,scoring='balanced_accuracy'\n)\n\n\nmodel_random_search.fit(X_train,y_train)\n    \ncolumn_results = [f\"param_{name}\" for name in param_distributions.keys()]\ncolumn_results += [\"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n\ncv_results = pd.DataFrame(model_random_search.cv_results_)\ncv_results = cv_results[column_results].sort_values(\"mean_test_score\", ascending=False)\n\nshorten_param = lambda param_name: param_name.rsplit(\"__\", 1)[1] if \"__\" in param_name else param_name\n    \ncv_results = cv_results.rename(shorten_param, axis=1)\ncv_results","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:45:31.15825Z","iopub.execute_input":"2022-06-08T09:45:31.158792Z","iopub.status.idle":"2022-06-08T09:47:57.980516Z","shell.execute_reply.started":"2022-06-08T09:45:31.158746Z","shell.execute_reply":"2022-06-08T09:47:57.979562Z"}}},{"cell_type":"markdown","source":"from pprint import pprint\nprint(\"The best parameters are:\")\npprint(model_random_search.best_params_)\nprint(f\"\\n with a mean test score (accuracy) of : {cv_results.iloc[0]['mean_test_score']:.3f} +- {cv_results.iloc[0]['std_test_score']:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:49:01.108781Z","iopub.execute_input":"2022-06-08T09:49:01.110105Z","iopub.status.idle":"2022-06-08T09:49:01.118392Z","shell.execute_reply.started":"2022-06-08T09:49:01.110034Z","shell.execute_reply":"2022-06-08T09:49:01.117392Z"}}},{"cell_type":"code","source":"#model = model_random_search.best_estimator_ # we select the best model ","metadata":{"execution":{"iopub.status.busy":"2022-06-08T12:45:56.353139Z","iopub.execute_input":"2022-06-08T12:45:56.353602Z","iopub.status.idle":"2022-06-08T12:45:56.358793Z","shell.execute_reply.started":"2022-06-08T12:45:56.353555Z","shell.execute_reply":"2022-06-08T12:45:56.357777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can check how this model performs on our test data sample","metadata":{}},{"cell_type":"markdown","source":"It's normal for the score to be smaller","metadata":{}},{"cell_type":"code","source":"#model.fit(X_train,y_train)\naccuracy = model.score(X_test,y_test)\nprint(f\"The test accuracy score of the best model is {accuracy:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-08T15:48:26.719Z","iopub.execute_input":"2022-06-08T15:48:26.719418Z","iopub.status.idle":"2022-06-08T15:48:26.956834Z","shell.execute_reply.started":"2022-06-08T15:48:26.719384Z","shell.execute_reply":"2022-06-08T15:48:26.955818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that by refitting the model on the whole train data set, we get the same accuracy. That is because once the outer/iner cross validation is performed with the randomized search, the algorithm automatically Refits the full train data set with the best parameters found","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"faire un cross validate sur des données où on a fait un hyper parameter tuning a t il du sens ? ca me parait un peu biaisé\n\n\nun nested cross validation permet d'estimer les generalistions de performances mais au final ne permet pas de décider exactement quels hyperparametrezs utiliser. En effet, prenons l'exemple d'une outer loop de 5 folds. Pour chaque outer fold, on a un test set et un train set. Le train set est dedécoupé en X inner folds pour l'hyperparameter tunning et une fois les best parameters trouvés, le modele est reentrainé sur tout le train set de cet inner fold et le score déterminé sur le test set.\n\nA chaque outer fold, on refait cette procédure mais il n'y a aucune raison pour que les hyperparametres soient les memes d'un outerfold à un autre. ","metadata":{"execution":{"iopub.status.busy":"2022-06-01T15:35:30.647243Z","iopub.execute_input":"2022-06-01T15:35:30.648603Z","iopub.status.idle":"2022-06-01T15:35:30.656091Z","shell.execute_reply.started":"2022-06-01T15:35:30.64856Z","shell.execute_reply":"2022-06-01T15:35:30.654856Z"}}},{"cell_type":"markdown","source":"#cela n'a en principe aucun sens de refaire un cross validate su X_train,y_train. En effet, admettons qu'on utilise le meme cv avec le meme random state:\n# on va refaire les meme folds lors du parameter tunning et vu que les best parameters obtenus faisaient evidemment parti de ceux testes\n# on va se retrouver avec le meme score.\n\n# par contre ce qui peut faire sens, c'est qu'on a arbitraiement pris un X_train et X_test via train test split au debut\n# on peut faire un cross_validate sur X et y mais je sais pas pourquoi ce m'a pas l'air net.\n# en meme temps on en a besoin pour comparer les train et test scores poru checker overfitting....\n\n#model.set_params(classifier__l2_regularization=1000)\ncv_results = cross_validate(model,X_train,y_train,cv=cv_outer,error_score='raise',scoring=\"balanced_accuracy\", return_train_score=True)\nfor name in [\"train\", \"test\"]:\n    r = cv_results[f'{name}_score'] \n    print(f\"Score {name}: {r.mean():.3f} +/- {r.std():.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-01T15:42:18.200642Z","iopub.execute_input":"2022-06-01T15:42:18.201056Z","iopub.status.idle":"2022-06-01T15:43:06.587115Z","shell.execute_reply.started":"2022-06-01T15:42:18.201022Z","shell.execute_reply":"2022-06-01T15:43:06.586082Z"}}},{"cell_type":"markdown","source":"\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T12:09:02.209334Z","iopub.execute_input":"2022-05-31T12:09:02.210144Z","iopub.status.idle":"2022-05-31T12:10:02.498498Z","shell.execute_reply.started":"2022-05-31T12:09:02.210097Z","shell.execute_reply":"2022-05-31T12:10:02.497387Z"}}},{"cell_type":"code","source":"from sklearn.inspection import permutation_importance\n\nresult = permutation_importance(\n    model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T15:48:31.66226Z","iopub.execute_input":"2022-06-08T15:48:31.662729Z","iopub.status.idle":"2022-06-08T15:48:54.527283Z","shell.execute_reply.started":"2022-06-08T15:48:31.662693Z","shell.execute_reply":"2022-06-08T15:48:54.526189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted_importances_idx = result.importances_mean.argsort()\nimportances = pd.DataFrame(\n    result.importances[sorted_importances_idx].T,\n    columns=X.columns[sorted_importances_idx],\n)\nax = importances.plot.box(vert=False, whis=30)\nax.set_title(\"Permutation Importances (test set)\")\nax.axvline(x=0, color=\"k\", linestyle=\"--\")\nax.set_xlabel(\"Decrease in accuracy score\")\nax.figure.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-06-08T12:46:51.685933Z","iopub.execute_input":"2022-06-08T12:46:51.686337Z","iopub.status.idle":"2022-06-08T12:46:52.197796Z","shell.execute_reply.started":"2022-06-08T12:46:51.6863Z","shell.execute_reply":"2022-06-08T12:46:52.196609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model[1].feature_importances = list(sorted_importances_idx)\nmodel[1].k = 17\nmodel[1].reverse = True\ncv_results = cross_validate(model,X_train,y_train,cv=cv_outer,error_score='raise',scoring=\"balanced_accuracy\", return_train_score=True)\nfor name in [\"train\", \"test\"]:\n    r = cv_results[f'{name}_score'] \n    print(f\"Score {name}: {r.mean():.3f} +/- {r.std():.3f}\")\n   ","metadata":{"execution":{"iopub.status.busy":"2022-06-08T12:52:04.269118Z","iopub.execute_input":"2022-06-08T12:52:04.269504Z","iopub.status.idle":"2022-06-08T12:52:38.012937Z","shell.execute_reply.started":"2022-06-08T12:52:04.269474Z","shell.execute_reply":"2022-06-08T12:52:38.01156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\ny_train_pred = cross_val_predict(model,X_train,y_train,cv=cv_outer)\nfrom sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score\nconfusion_matrix(y_train,y_train_pred)\nprint(f\"precision_score = {precision_score(y_train,y_train_pred):.3f}\")\nprint(f\"recall_score = {recall_score(y_train,y_train_pred):.3f}\")\nprint(f\"f1_score = {f1_score(y_train,y_train_pred):.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-08T12:47:17.72546Z","iopub.status.idle":"2022-06-08T12:47:17.726455Z","shell.execute_reply.started":"2022-06-08T12:47:17.726242Z","shell.execute_reply":"2022-06-08T12:47:17.726266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = GradientBoostingClassifier()\nmodel.fit(X, y)\nsubmission_predictions = model.predict(X_sub)\n\noutput = pd.DataFrame({'PassengerId': X_sub.PassengerId, 'Transported': submission_predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-06-08T12:47:17.727658Z","iopub.status.idle":"2022-06-08T12:47:17.72852Z","shell.execute_reply.started":"2022-06-08T12:47:17.728308Z","shell.execute_reply":"2022-06-08T12:47:17.72833Z"},"trusted":true},"execution_count":null,"outputs":[]}]}