{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version : 1.0.2\n",
      "C:\\Users\\qarna\\Desktop\\kaggle\\kaggle\\input\\spaceship-titanic\\train.csv \n",
      " C:\\Users\\qarna\\Desktop\\kaggle\\kaggle\\input\\spaceship-titanic\\test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "print(f\"sklearn version : {sklearn.__version__}\")\n",
    "\n",
    "# just adding a comment\n",
    "Project = 'spaceship-titanic'\n",
    "\n",
    "#/kaggle/working\n",
    "online = os.getcwd()=='/kaggle/working'\n",
    "#/kaggle\n",
    "parrent_directory = os.path.split(initial_directory)[0]\n",
    "#whether we are working online or locally,os.path.join allows us to deal easily with \n",
    "\n",
    "train_file = os.path.join(parrent_directory,'kaggle','input',Project,\"train.csv\")\n",
    "test_file = os.path.join(parrent_directory,'kaggle','input',Project,\"test.csv\")\n",
    "print(train_file,\"\\n\",test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T16:03:43.623815Z",
     "iopub.status.busy": "2022-06-08T16:03:43.62326Z",
     "iopub.status.idle": "2022-06-08T16:03:43.62941Z",
     "shell.execute_reply": "2022-06-08T16:03:43.628354Z",
     "shell.execute_reply.started": "2022-06-08T16:03:43.623776Z"
    }
   },
   "outputs": [],
   "source": [
    "Debugg=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2022-06-08T16:03:45.825893Z",
     "iopub.status.busy": "2022-06-08T16:03:45.824763Z",
     "iopub.status.idle": "2022-06-08T16:03:45.836499Z",
     "shell.execute_reply": "2022-06-08T16:03:45.835312Z",
     "shell.execute_reply.started": "2022-06-08T16:03:45.825848Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_new_variables(data):\n",
    "    data['Group'] = data.PassengerId.apply(lambda x : x[0:4])\n",
    "    data['Group'] = data.groupby('Group')['Group'].transform('count')\n",
    "\n",
    "    Luxury_variables = ['RoomService','Spa','VRDeck','FoodCourt','ShoppingMall']\n",
    "    data[\"Luxury\"] = data[Luxury_variables].sum(axis=1)\n",
    "\n",
    "    data[\"nbnan\"] = data.isnull().sum(axis=1)\n",
    "    \n",
    "    data['last_name'] = data['Name'].apply(lambda x:str(x).split(\" \")[-1])\n",
    "    data.last_name.value_counts()\n",
    "    data['N_Familly_members'] = data.groupby('last_name')['last_name'].transform('count')\n",
    "    #data['Luxury_Familly'] = data.groupby('last_name')['Luxury'].transform('sum')\n",
    "    data.set_index('PassengerId')\n",
    "    \n",
    "    newvars  = pd.DataFrame(data[\"Cabin\"].str.split('/', expand=True).values,columns=['Cabin_Deck','Cabin_Number','Cabin_Side'])\n",
    "    data = pd.concat([data,newvars],axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T16:03:49.904399Z",
     "iopub.status.busy": "2022-06-08T16:03:49.903974Z",
     "iopub.status.idle": "2022-06-08T16:03:49.915264Z",
     "shell.execute_reply": "2022-06-08T16:03:49.914077Z",
     "shell.execute_reply.started": "2022-06-08T16:03:49.904367Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def indices_of_top_k(arr, k,reverse=False):\n",
    "    if(reverse==False):\n",
    "        z = np.array(arr)[0:k]\n",
    "    else:\n",
    "        z = np.array(arr)[-k-1:]\n",
    "    return np.sort(z)\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_importances=None, k=None,reverse=False):\n",
    "        self.feature_importances = feature_importances\n",
    "        self.k = k\n",
    "        self.reverse = reverse\n",
    "    def fit(self, X, y=None):\n",
    "        if(self.feature_importances!=None):\n",
    "            self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k,self.reverse)     \n",
    "                \n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if(self.feature_importances!=None and self.k!=None):\n",
    "            return X[:, self.feature_indices_]\n",
    "        else :\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T16:03:52.348642Z",
     "iopub.status.busy": "2022-06-08T16:03:52.348227Z",
     "iopub.status.idle": "2022-06-08T16:03:52.747254Z",
     "shell.execute_reply": "2022-06-08T16:03:52.746258Z",
     "shell.execute_reply.started": "2022-06-08T16:03:52.348611Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(train_file)\n",
    "data_sub = pd.read_csv(test_file)\n",
    "\n",
    "if(Debugg):\n",
    "    data = data.iloc[:30]\n",
    "    data_sub = data_sub.iloc[:30]\n",
    "X_sub = data_sub\n",
    "\n",
    "data = add_new_variables(data)\n",
    "data_sub = add_new_variables(data_sub)\n",
    "X_sub = add_new_variables(X_sub)\n",
    "\n",
    "Target_name = 'Transported'\n",
    "y = data[Target_name]\n",
    "X = data.drop(columns=[Target_name])\n",
    "\n",
    "#\"nbnan\",\"ShoppingMall\"\n",
    "columns_to_drop = [\"Cabin\",\"Name\",'last_name']\n",
    "X = X.drop(columns=columns_to_drop)\n",
    "X_sub = X_sub.drop(columns=columns_to_drop)\n",
    "\n",
    "X = X.drop(columns=['PassengerId'])\n",
    "\n",
    "numerical_columns = X.select_dtypes(exclude=['object']).columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "def clean_data(dt):\n",
    "    #we first use the information we have gathered so far:\n",
    "    #People from Cabin_Deck==G are al from Europa as shown from : sns.histplot(data=data,x='Cabin_Deck',hue='HomePlanet')\n",
    "    mask1 = (dt['Cabin_Deck']=='G')\n",
    "    mask2 = dt.HomePlanet.isnull()\n",
    "    mask = (mask1) & (mask2)\n",
    "    dt.loc[mask,'HomePlanet'] = 'Earth' \n",
    "    \n",
    "    mask1 = (dt['HomePlanet']=='Earth')\n",
    "    mask2 = dt.Cabin_Deck.isnull()\n",
    "    mask = (mask1) & (mask2)\n",
    "    dt.loc[mask,'Cabin_Deck'] = 'G' \n",
    "    \n",
    "    # Il n'y a pas de VIP qui ont Earth en HomePlanet : sns.catplot(data=data,x='VIP',col='HomePlanet',kind='count')\n",
    "    mask1 = (dt['HomePlanet']=='Earth')\n",
    "    mask2 = dt.VIP.isnull()\n",
    "    mask = (mask1) & (mask2)\n",
    "    dt.loc[mask,'VIP'] = False\n",
    "    \n",
    "    # aucun des VIP n'est en CryoSleep : sns.histplot(data=X,y='VIP',hue='CryoSleep',multiple='stack')\n",
    "    mask1 = (dt['CryoSleep']==False)\n",
    "    mask2 = dt.VIP.isnull()\n",
    "    mask = (mask1) & (mask2)\n",
    "    dt.loc[mask,'VIP'] = True \n",
    "    \n",
    "    mask = (dt['VIP']==True)\n",
    "    mask2 = dt.CryoSleep.isnull()\n",
    "    mask = (mask1) & (mask2)\n",
    "    dt.loc[mask,'CryoSleep'] = False\n",
    "    \n",
    "    # les gends des decks A B et C sont tous d'europe : sns.histplot(data=data,x='Cabin_Deck',hue='HomePlanet')\n",
    "    mask1 = (dt.Cabin_Deck.isin(['A','B','C']))\n",
    "    mask2 = dt.HomePlanet.isnull()\n",
    "    mask = (mask1) & (mask2)\n",
    "    dt.loc[mask,'HomePlanet']='Europa'\n",
    "    \n",
    "    #Les enfants d'un Age nférieur ou égal à 12 ans n'ont rien dépensé\n",
    "    mask1 = dt.Age<=12\n",
    "    for col in ['RoomService','Spa','VRDeck','FoodCourt','ShoppingMall']:\n",
    "        mask2 = dt[col].isnull()\n",
    "        mask = (mask1) & (mask2)\n",
    "        dt.loc[mask,col]= 0\n",
    "        \n",
    "    \n",
    "    Luxury_variables = ['RoomService','Spa','VRDeck','FoodCourt','ShoppingMall']\n",
    "    dt[\"Luxury\"] = dt[Luxury_variables].sum(axis=1)\n",
    "    \n",
    "    dt.loc[(dt.CryoSleep.isnull()) & (dt.Luxury == 0), 'CryoSleep'] = True\n",
    "    dt.loc[(dt.CryoSleep.isnull()) & (dt.Luxury != 0), 'CryoSleep'] = False\n",
    "    \n",
    "    # si l'age est manquant, le selectionner sur la base des habitants de la meme planete    \n",
    "    dt['Age']=dt['Age'].fillna(dt.groupby('HomePlanet')['Age'].transform(\"median\"))\n",
    "    \n",
    "    dt[numerical_columns] = dt[numerical_columns].fillna(dt[numerical_columns].median())\n",
    "    dt[categorical_columns] = dt[categorical_columns].fillna('Unknown').astype('string')\n",
    "    return dt\n",
    "\n",
    "X = clean_data(X)\n",
    "X_sub = clean_data(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T15:47:20.339661Z",
     "iopub.status.busy": "2022-06-08T15:47:20.339239Z",
     "iopub.status.idle": "2022-06-08T15:47:21.206621Z",
     "shell.execute_reply": "2022-06-08T15:47:21.205807Z",
     "shell.execute_reply.started": "2022-06-08T15:47:20.339628Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T15:47:28.296416Z",
     "iopub.status.busy": "2022-06-08T15:47:28.295677Z",
     "iopub.status.idle": "2022-06-08T15:47:28.343074Z",
     "shell.execute_reply": "2022-06-08T15:47:28.342313Z",
     "shell.execute_reply.started": "2022-06-08T15:47:28.296377Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T14:33:53.107047Z",
     "iopub.status.busy": "2022-06-08T14:33:53.106616Z",
     "iopub.status.idle": "2022-06-08T14:33:53.466166Z",
     "shell.execute_reply": "2022-06-08T14:33:53.464852Z",
     "shell.execute_reply.started": "2022-06-08T14:33:53.10701Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sns.histplot(data=data[data.Luxury==0],x='Age',ax=ax)\n",
    "sns.histplot(data=data[data.Luxury!=0],x='Age',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T14:46:05.086095Z",
     "iopub.status.busy": "2022-06-08T14:46:05.085664Z",
     "iopub.status.idle": "2022-06-08T14:46:05.14414Z",
     "shell.execute_reply": "2022-06-08T14:46:05.142983Z",
     "shell.execute_reply.started": "2022-06-08T14:46:05.086062Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_data(data).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T14:52:14.368546Z",
     "iopub.status.busy": "2022-06-08T14:52:14.367956Z",
     "iopub.status.idle": "2022-06-08T14:52:14.647232Z",
     "shell.execute_reply": "2022-06-08T14:52:14.646394Z",
     "shell.execute_reply.started": "2022-06-08T14:52:14.368499Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=data,x='Destination',hue='HomePlanet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T15:49:39.942219Z",
     "iopub.status.busy": "2022-06-08T15:49:39.941785Z",
     "iopub.status.idle": "2022-06-08T15:49:40.064961Z",
     "shell.execute_reply": "2022-06-08T15:49:40.063822Z",
     "shell.execute_reply.started": "2022-06-08T15:49:39.942185Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "categorical_preprocessor = Pipeline([\n",
    "    #('impcat',SimpleImputer()),#,strategy='constant',fill_value=\"missing_value\")),  # ca ne marche pas car mussing_value set considéré comme un string alors que les autres variables sont objet.\n",
    "    ('enc',OrdinalEncoder(handle_unknown=\"use_encoded_value\",unknown_value=-1)),\n",
    "     ])\n",
    "\n",
    "numerical_preprocessor = Pipeline([\n",
    "    #('impnum',SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "    ('sca',StandardScaler()),\n",
    "])\n",
    "    \n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('cat_preprocessor', categorical_preprocessor, categorical_columns),\n",
    "        ('num_preprocessor', numerical_preprocessor, numerical_columns),\n",
    "       \n",
    "    ],#sparse_threshold=0, remainder='passthrough',\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=400, max_leaf_nodes=10,n_jobs=-1, random_state=42)\n",
    "#classifier = SGDClassifier(alpha=0.01,random_state=42)\n",
    "#classifier = HistGradientBoostingClassifier(learning_rate=0.005, max_leaf_nodes=20, early_stopping=True, n_iter_no_change=5, max_iter=1000)\n",
    "\n",
    "estimators = [\n",
    "    (\"hist\",HistGradientBoostingClassifier(learning_rate=0.005, max_leaf_nodes=20, early_stopping=True, n_iter_no_change=5, max_iter=1000,random_state=42)),\n",
    "    (\"forest\",RandomForestClassifier(bootstrap=True,n_estimators=600,max_depth=16,max_leaf_nodes=10,n_jobs=-1, random_state=42,min_samples_leaf=1)),\n",
    "   # (\"knn\",KNeighborsClassifier(n_neighbors=40)),\n",
    "    #(\"sgd\",SGDClassifier(alpha=0.01,random_state=42)),\n",
    "    #(\"log\",LogisticRegression(random_state=42,max_iter=1000)),\n",
    "   # (\"xgb\",XGBClassifier(eta=0.005,max_depth=10))\n",
    "]\n",
    "classifier = VotingClassifier(estimators, voting='soft')\n",
    "\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"TopFeatureSelector\",TopFeatureSelector(feature_importances=None, k=None)),\n",
    "    (\"classifier\",  classifier),\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cv_inner = StratifiedKFold(n_splits=5,shuffle=True,random_state=42) #mega important\n",
    "cv_outer = StratifiedKFold(n_splits=5,shuffle=True,random_state=42) #mega important\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,shuffle=True)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T15:49:42.801068Z",
     "iopub.status.busy": "2022-06-08T15:49:42.800299Z",
     "iopub.status.idle": "2022-06-08T15:49:57.214263Z",
     "shell.execute_reply": "2022-06-08T15:49:57.212842Z",
     "shell.execute_reply.started": "2022-06-08T15:49:42.801008Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model,X_train,y_train,cv=cv_outer,error_score='raise',scoring=\"balanced_accuracy\", return_train_score=True)\n",
    "for name in [\"train\", \"test\"]:\n",
    "    r = cv_results[f'{name}_score'] \n",
    "    print(f\"Score {name}: {r.mean():.3f} +/- {r.std():.3f}\")\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(model,X_train,y_train,cv=cv_outer)\n",
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score\n",
    "confusion_matrix(y_train,y_train_pred)\n",
    "print(f\"precision_score = {precision_score(y_train,y_train_pred):.3f}\")\n",
    "print(f\"recall_score = {recall_score(y_train,y_train_pred):.3f}\")\n",
    "print(f\"f1_score = {f1_score(y_train,y_train_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T15:48:21.324595Z",
     "iopub.status.busy": "2022-06-08T15:48:21.324128Z",
     "iopub.status.idle": "2022-06-08T15:48:22.487886Z",
     "shell.execute_reply": "2022-06-08T15:48:22.48681Z",
     "shell.execute_reply.started": "2022-06-08T15:48:21.324553Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T09:45:31.158792Z",
     "iopub.status.busy": "2022-06-08T09:45:31.15825Z",
     "iopub.status.idle": "2022-06-08T09:47:57.980516Z",
     "shell.execute_reply": "2022-06-08T09:47:57.979562Z",
     "shell.execute_reply.started": "2022-06-08T09:45:31.158746Z"
    }
   },
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = np.linspace(200,1000,100,dtype=int).tolist()\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = np.linspace(5, 30,26).tolist()+['None']\n",
    "min_samples_leaf = [1, 2, 4,8]\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "\n",
    "param_distributions = {\n",
    "    'classifier__forest__n_estimators': n_estimators,\n",
    "    'classifier__forest__max_features': max_features,\n",
    "    'classifier__forest__max_depth': max_depth,\n",
    "    'classifier__forest__min_samples_leaf': min_samples_leaf,\n",
    "    'classifier__forest__bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "model_random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_distributions, n_iter=30,cv=cv_inner, verbose=1,n_jobs = -1,scoring='balanced_accuracy'\n",
    ")\n",
    "\n",
    "\n",
    "model_random_search.fit(X_train,y_train)\n",
    "    \n",
    "column_results = [f\"param_{name}\" for name in param_distributions.keys()]\n",
    "column_results += [\"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "\n",
    "cv_results = pd.DataFrame(model_random_search.cv_results_)\n",
    "cv_results = cv_results[column_results].sort_values(\"mean_test_score\", ascending=False)\n",
    "\n",
    "shorten_param = lambda param_name: param_name.rsplit(\"__\", 1)[1] if \"__\" in param_name else param_name\n",
    "    \n",
    "cv_results = cv_results.rename(shorten_param, axis=1)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T09:49:01.110105Z",
     "iopub.status.busy": "2022-06-08T09:49:01.108781Z",
     "iopub.status.idle": "2022-06-08T09:49:01.118392Z",
     "shell.execute_reply": "2022-06-08T09:49:01.117392Z",
     "shell.execute_reply.started": "2022-06-08T09:49:01.110034Z"
    }
   },
   "source": [
    "from pprint import pprint\n",
    "print(\"The best parameters are:\")\n",
    "pprint(model_random_search.best_params_)\n",
    "print(f\"\\n with a mean test score (accuracy) of : {cv_results.iloc[0]['mean_test_score']:.3f} +- {cv_results.iloc[0]['std_test_score']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T12:45:56.353602Z",
     "iopub.status.busy": "2022-06-08T12:45:56.353139Z",
     "iopub.status.idle": "2022-06-08T12:45:56.358793Z",
     "shell.execute_reply": "2022-06-08T12:45:56.357777Z",
     "shell.execute_reply.started": "2022-06-08T12:45:56.353555Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = model_random_search.best_estimator_ # we select the best model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how this model performs on our test data sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's normal for the score to be smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T15:48:26.719418Z",
     "iopub.status.busy": "2022-06-08T15:48:26.719Z",
     "iopub.status.idle": "2022-06-08T15:48:26.956834Z",
     "shell.execute_reply": "2022-06-08T15:48:26.955818Z",
     "shell.execute_reply.started": "2022-06-08T15:48:26.719384Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.fit(X_train,y_train)\n",
    "accuracy = model.score(X_test,y_test)\n",
    "print(f\"The test accuracy score of the best model is {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by refitting the model on the whole train data set, we get the same accuracy. That is because once the outer/iner cross validation is performed with the randomized search, the algorithm automatically Refits the full train data set with the best parameters found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T15:35:30.648603Z",
     "iopub.status.busy": "2022-06-01T15:35:30.647243Z",
     "iopub.status.idle": "2022-06-01T15:35:30.656091Z",
     "shell.execute_reply": "2022-06-01T15:35:30.654856Z",
     "shell.execute_reply.started": "2022-06-01T15:35:30.64856Z"
    }
   },
   "source": [
    "faire un cross validate sur des données où on a fait un hyper parameter tuning a t il du sens ? ca me parait un peu biaisé\n",
    "\n",
    "\n",
    "un nested cross validation permet d'estimer les generalistions de performances mais au final ne permet pas de décider exactement quels hyperparametrezs utiliser. En effet, prenons l'exemple d'une outer loop de 5 folds. Pour chaque outer fold, on a un test set et un train set. Le train set est dedécoupé en X inner folds pour l'hyperparameter tunning et une fois les best parameters trouvés, le modele est reentrainé sur tout le train set de cet inner fold et le score déterminé sur le test set.\n",
    "\n",
    "A chaque outer fold, on refait cette procédure mais il n'y a aucune raison pour que les hyperparametres soient les memes d'un outerfold à un autre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T15:42:18.201056Z",
     "iopub.status.busy": "2022-06-01T15:42:18.200642Z",
     "iopub.status.idle": "2022-06-01T15:43:06.587115Z",
     "shell.execute_reply": "2022-06-01T15:43:06.586082Z",
     "shell.execute_reply.started": "2022-06-01T15:42:18.201022Z"
    }
   },
   "source": [
    "#cela n'a en principe aucun sens de refaire un cross validate su X_train,y_train. En effet, admettons qu'on utilise le meme cv avec le meme random state:\n",
    "# on va refaire les meme folds lors du parameter tunning et vu que les best parameters obtenus faisaient evidemment parti de ceux testes\n",
    "# on va se retrouver avec le meme score.\n",
    "\n",
    "# par contre ce qui peut faire sens, c'est qu'on a arbitraiement pris un X_train et X_test via train test split au debut\n",
    "# on peut faire un cross_validate sur X et y mais je sais pas pourquoi ce m'a pas l'air net.\n",
    "# en meme temps on en a besoin pour comparer les train et test scores poru checker overfitting....\n",
    "\n",
    "#model.set_params(classifier__l2_regularization=1000)\n",
    "cv_results = cross_validate(model,X_train,y_train,cv=cv_outer,error_score='raise',scoring=\"balanced_accuracy\", return_train_score=True)\n",
    "for name in [\"train\", \"test\"]:\n",
    "    r = cv_results[f'{name}_score'] \n",
    "    print(f\"Score {name}: {r.mean():.3f} +/- {r.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-31T12:09:02.210144Z",
     "iopub.status.busy": "2022-05-31T12:09:02.209334Z",
     "iopub.status.idle": "2022-05-31T12:10:02.498498Z",
     "shell.execute_reply": "2022-05-31T12:10:02.497387Z",
     "shell.execute_reply.started": "2022-05-31T12:09:02.210097Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T15:48:31.662729Z",
     "iopub.status.busy": "2022-06-08T15:48:31.66226Z",
     "iopub.status.idle": "2022-06-08T15:48:54.527283Z",
     "shell.execute_reply": "2022-06-08T15:48:54.526189Z",
     "shell.execute_reply.started": "2022-06-08T15:48:31.662693Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(\n",
    "    model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T12:46:51.686337Z",
     "iopub.status.busy": "2022-06-08T12:46:51.685933Z",
     "iopub.status.idle": "2022-06-08T12:46:52.197796Z",
     "shell.execute_reply": "2022-06-08T12:46:52.196609Z",
     "shell.execute_reply.started": "2022-06-08T12:46:51.6863Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=X.columns[sorted_importances_idx],\n",
    ")\n",
    "ax = importances.plot.box(vert=False, whis=30)\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T12:52:04.269504Z",
     "iopub.status.busy": "2022-06-08T12:52:04.269118Z",
     "iopub.status.idle": "2022-06-08T12:52:38.012937Z",
     "shell.execute_reply": "2022-06-08T12:52:38.01156Z",
     "shell.execute_reply.started": "2022-06-08T12:52:04.269474Z"
    }
   },
   "outputs": [],
   "source": [
    "model[1].feature_importances = list(sorted_importances_idx)\n",
    "model[1].k = 17\n",
    "model[1].reverse = True\n",
    "cv_results = cross_validate(model,X_train,y_train,cv=cv_outer,error_score='raise',scoring=\"balanced_accuracy\", return_train_score=True)\n",
    "for name in [\"train\", \"test\"]:\n",
    "    r = cv_results[f'{name}_score'] \n",
    "    print(f\"Score {name}: {r.mean():.3f} +/- {r.std():.3f}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T12:47:17.72546Z",
     "iopub.status.idle": "2022-06-08T12:47:17.726455Z",
     "shell.execute_reply": "2022-06-08T12:47:17.726266Z",
     "shell.execute_reply.started": "2022-06-08T12:47:17.726242Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(model,X_train,y_train,cv=cv_outer)\n",
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score\n",
    "confusion_matrix(y_train,y_train_pred)\n",
    "print(f\"precision_score = {precision_score(y_train,y_train_pred):.3f}\")\n",
    "print(f\"recall_score = {recall_score(y_train,y_train_pred):.3f}\")\n",
    "print(f\"f1_score = {f1_score(y_train,y_train_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-08T12:47:17.727658Z",
     "iopub.status.idle": "2022-06-08T12:47:17.72852Z",
     "shell.execute_reply": "2022-06-08T12:47:17.72833Z",
     "shell.execute_reply.started": "2022-06-08T12:47:17.728308Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = GradientBoostingClassifier()\n",
    "model.fit(X, y)\n",
    "submission_predictions = model.predict(X_sub)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': X_sub.PassengerId, 'Transported': submission_predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
